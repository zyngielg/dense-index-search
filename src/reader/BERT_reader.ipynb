{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZD3XuDYHlJqm",
        "Ws05JS_vlOhO",
        "76YoqtY7p8ct",
        "BgC-63OcqCJL",
        "UkilZEI99J5U",
        "zfBu2t5d9Ojd",
        "c2XxaCul9Re-",
        "WzAODV12ZA1h"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cde4de5a21294e889901528cafac5f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98714877c70341ec8e50b62739af9d83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a23bdb1a69845c596ed35a6d94a28d4",
              "IPY_MODEL_f4dc7ec89bd941f8aa5c51a25b922612"
            ]
          }
        },
        "98714877c70341ec8e50b62739af9d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a23bdb1a69845c596ed35a6d94a28d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c8f617db98a426fbfdd9c6fede753ff",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5de33aeb3040479c938bfa1658eebf56"
          }
        },
        "f4dc7ec89bd941f8aa5c51a25b922612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7358d1e4f7184a8eb50a93f92aece226",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 9.81kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4598b192c96247488d8bb350dad9313d"
          }
        },
        "8c8f617db98a426fbfdd9c6fede753ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5de33aeb3040479c938bfa1658eebf56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7358d1e4f7184a8eb50a93f92aece226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4598b192c96247488d8bb350dad9313d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d73ecc29deb4ff79cd24a29df801832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fe0738b1f284dada35965a4f6c49791",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_38ee25918b3f4011bef5ffd40ee55858",
              "IPY_MODEL_dbba11aa124f44e297d2c89685326c21"
            ]
          }
        },
        "8fe0738b1f284dada35965a4f6c49791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38ee25918b3f4011bef5ffd40ee55858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c70b7c3dc9d8449099f6dabe5a5af32c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55797d11c5f94fcba4c9caf6dc000626"
          }
        },
        "dbba11aa124f44e297d2c89685326c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87be7e2ceec94391b1c258b53362cc8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:04&lt;00:00, 48.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48cd4ac2b73c44bd8a9ad9e7e66f7956"
          }
        },
        "c70b7c3dc9d8449099f6dabe5a5af32c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55797d11c5f94fcba4c9caf6dc000626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87be7e2ceec94391b1c258b53362cc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48cd4ac2b73c44bd8a9ad9e7e66f7956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "307bbf959845492aaca909a78ecc370f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_310634794a0f47a6b933cb1f599fc515",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18ee8816e8624988bf51635b5d11d48d",
              "IPY_MODEL_357d723d2b69477c92ee117fb379f604"
            ]
          }
        },
        "310634794a0f47a6b933cb1f599fc515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18ee8816e8624988bf51635b5d11d48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bd15e13fba44157abd7cbe6e9ea2779",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48413323a1b941e784ad501069cb60a1"
          }
        },
        "357d723d2b69477c92ee117fb379f604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abedf67f54c846a4928e9700e9d57e06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:02&lt;00:00, 170kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eff86a8f22634b15b4800622e8713da7"
          }
        },
        "0bd15e13fba44157abd7cbe6e9ea2779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48413323a1b941e784ad501069cb60a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abedf67f54c846a4928e9700e9d57e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eff86a8f22634b15b4800622e8713da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd6c371361684ab08dbb63688d59c69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68dc7c2035394f4db7107e55f5605495",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ecfdbb41c7e4074a0da0ceccdf5074b",
              "IPY_MODEL_471de2bea25a43dda3f9d55f3fed0c62"
            ]
          }
        },
        "68dc7c2035394f4db7107e55f5605495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ecfdbb41c7e4074a0da0ceccdf5074b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb0ccbfd5c5c49f2a62f57a016600e47",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f80cf9f737242c3bd2a8585623da3fc"
          }
        },
        "471de2bea25a43dda3f9d55f3fed0c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b24dadbb8c794e1bb7bb6063f28d49a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:06&lt;00:00, 4.50B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f882ca9fb9d44d5dac6e60bee9f1af0c"
          }
        },
        "eb0ccbfd5c5c49f2a62f57a016600e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f80cf9f737242c3bd2a8585623da3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b24dadbb8c794e1bb7bb6063f28d49a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f882ca9fb9d44d5dac6e60bee9f1af0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "918e8de71eb94b698def2492c634c5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68aea9ca8e9c44c4bece2875eb2255d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9de9b2befbed4cc491679517123adf22",
              "IPY_MODEL_d2ca6202b0fe4ff0aa3adc48900ac643"
            ]
          }
        },
        "68aea9ca8e9c44c4bece2875eb2255d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9de9b2befbed4cc491679517123adf22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_165cd6ac16c546af9ceb1e15d5346703",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_420e533886a1408989e1b92dc69ae16f"
          }
        },
        "d2ca6202b0fe4ff0aa3adc48900ac643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7040af81148e4bb19ad2065007582db3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:16&lt;00:00, 27.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0ce8f7fb1a24285b47d2e32e37f4d43"
          }
        },
        "165cd6ac16c546af9ceb1e15d5346703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "420e533886a1408989e1b92dc69ae16f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7040af81148e4bb19ad2065007582db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0ce8f7fb1a24285b47d2e32e37f4d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "247277de237d485d8e4abd8f15bdac2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_811471e906194f6491efac2a9a99e1ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a48a44a15db493ca022a40561a1d525",
              "IPY_MODEL_bb78d0cd74a44b9390dc4407f49a846a"
            ]
          }
        },
        "811471e906194f6491efac2a9a99e1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a48a44a15db493ca022a40561a1d525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33f3b85c42414aba8961297f8ccffc4e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d4668a9a64240a4ad89a493aa4f3720"
          }
        },
        "bb78d0cd74a44b9390dc4407f49a846a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58572fef9e0943b4a9e469831713dbc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [02:12&lt;00:00, 3.26B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_630383a016a544528155f82eb0b3f0a7"
          }
        },
        "33f3b85c42414aba8961297f8ccffc4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d4668a9a64240a4ad89a493aa4f3720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58572fef9e0943b4a9e469831713dbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "630383a016a544528155f82eb0b3f0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "875402f45fe348888a55ea790dc1e99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b0ee37219c3405388c34c71a1d325a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14a087594557474bb67dcf271f06153b",
              "IPY_MODEL_58667c0f75c04be790059be8d85892da"
            ]
          }
        },
        "9b0ee37219c3405388c34c71a1d325a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14a087594557474bb67dcf271f06153b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee71d40cfc7a44a490f1b67fde6d926e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ceeabe6a14664060ac68687ecf7cc802"
          }
        },
        "58667c0f75c04be790059be8d85892da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e92c12560d134bd8b8bbf10843d18f42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [02:12&lt;00:00, 3.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dddbb4d2d1884a6a9263fb54287ef0af"
          }
        },
        "ee71d40cfc7a44a490f1b67fde6d926e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ceeabe6a14664060ac68687ecf7cc802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e92c12560d134bd8b8bbf10843d18f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dddbb4d2d1884a6a9263fb54287ef0af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "txFuP0hGcCs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe501738-d186-4f68-e32c-b069b1d70ef9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/dense-index-retrieval/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/dense-index-retrieval\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD3XuDYHlJqm"
      },
      "source": [
        "## Packages and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpGHvJV-jrt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06ccc34-a72e-49af-d0d3-717ff4a1df8b"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install pickle5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 18.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219253 sha256=5f6e0eeb7b86507c2bcdcf6e8a243f1b5c8bb450d873bf47b6759d63f675b6a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDwmw7UDjl7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7004da0d-54ab-4acf-f42e-3ce00389e545"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pickle5 as pickle\n",
        "import nltk\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from datetime import datetime\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, SequentialSampler, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering, AutoModelForMultipleChoice, get_linear_schedule_with_warmup"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws05JS_vlOhO"
      },
      "source": [
        "## Pickle methods and content processing methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPUSOkKwCcnw"
      },
      "source": [
        "def save_data(data, file_path):\n",
        "    with open(file_path, 'wb') as handle:\n",
        "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_pickle(file_path):\n",
        "    with open(file_path, 'rb') as handle:\n",
        "        return pickle.load(handle)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47WJn1dzNRmd"
      },
      "source": [
        "# def letter_answer_to_index(answer):\n",
        "#   distribution = [0.0] * 5\n",
        "#   distribution[ord(answer) - 65] = 1.0\n",
        "#   return distribution\n",
        "\n",
        "def letter_answer_to_index(answer):\n",
        "  return ord(answer) - 65"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRdK22p0CorI"
      },
      "source": [
        "def preprocess_content(content, remove_stopwords, stemming, remove_punctuation):\n",
        "    if not remove_stopwords and not stemming and not remove_punctuation:\n",
        "        return content.lower()\n",
        "    if remove_punctuation:\n",
        "        content = content.translate(punctuation).replace('â€œ','').replace('â€™','')\n",
        "    snowball_stemmer = SnowballStemmer(language='english') \n",
        "    sentences = nltk.sent_tokenize(content.lower())\n",
        "    cleaned_sentences = []\n",
        "    \n",
        "    for sentence in sentences:\n",
        "        tokens = word_tokenize(sentence.lower())\n",
        "        if remove_stopwords:\n",
        "            tokens = [x for x in tokens if x not in stop_words]\n",
        "        if stemming:\n",
        "            tokens = [snowball_stemmer.stem(x) for x in tokens]\n",
        "        cleaned_sentences.append(' '.join(tokens))\n",
        "            \n",
        "    return ' '.join(cleaned_sentences)\n",
        "\n",
        "def preprocess_questions(questions, remove_stopwords, stemming, remove_punctuation, metamap=False):    \n",
        "    for question_id, question in tqdm(questions.items()):\n",
        "        processed_question = {\"question\": \"\", \"options\": {\"A\":\"\", \"B\":\"\",\"C\":\"\",\"D\":\"\",\"E\":\"\"}, \"answer\": \"\", \"metamap_phrases\": [], \"answer_idx\": \"\"}\n",
        "        processed_question['answer_idx'] = question[\"answer_idx\"]\n",
        "        processed_question['question'] = preprocess_content(question['question'], remove_stopwords, stemming, remove_punctuation)\n",
        "        for option, value in question['options'].items():\n",
        "            processed_question['options'][option] = preprocess_content(value, remove_stopwords, stemming, remove_punctuation)\n",
        "        if metamap:\n",
        "            processed_question['answer'] = preprocess_content(question['answer'], remove_stopwords, stemming, remove_punctuation)\n",
        "            for i, phrase in enumerate(question['metamap_phrases']):\n",
        "                processed_question['metamap_phrases'].append(preprocess_content(phrase, remove_stopwords, stemming, remove_punctuation))\n",
        "        questions[question_id] = processed_question\n",
        "\n",
        "def get_context(question_id, option, documents_collection=None):\n",
        "    try:\n",
        "      result = [x['evidence']['content'] for x in documents_collection[question_id]['retrieved_documents'][option.strip()]]\n",
        "      # if question == \"a 65-year-old asian man presents to his primary care physician because of abdominal distension, right upper quadrant (ruq) abdominal pain, decreased appetite, and weight loss for several weeks. he denies smoking or excess alcohol intake. his temperature is 37.1Â°c (98.7Â°f), blood pressure is 120/80 mm hg, and pulse is 85/min. physical examination reveals a cachectic man with jaundice, palmar erythema, ascites, and a palpable mass in the ruq. abdominal ultrasound shows a 3 cm hypoechoic mass in the right lobe of the liver. alpha fetoprotein (afp) is 500 Î¼g/l. which of the following is a risk factor for this patient condition?\":\n",
        "      #   print('nice')\n",
        "    except:\n",
        "      print(f\"Question ID: {question_id}\")\n",
        "      print(question_id in documents_collection.keys())\n",
        "\n",
        "      print(f\"Option: {option}s\")\n",
        "      print(f\"Option: {option.strip()}s\")\n",
        "      \n",
        "      print(option in documents_collection[question_id]['retrieved_documents'].keys())\n",
        "      print(f\"Options: {documents_collection[question_id]['retrieved_documents'].keys()}\")\n",
        "    if result == [] or result is None:\n",
        "      print(f\"Empty result for question: {question}\")\n",
        "      return \"No content\"\n",
        "    return ' '.join(result) "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76YoqtY7p8ct"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU9KZ8Yvb6uH"
      },
      "source": [
        "questions_dev_medqa_path = 'data/medqa/questions/metamap_extracted_phrases/dev.jsonl'\n",
        "questions_train_medqa_path ='data/medqa/questions/metamap_extracted_phrases/train.jsonl'\n",
        "questions_test_medqa_path ='data/medqa/questions/metamap_extracted_phrases/train.jsonl'\n",
        "\n",
        "# train\n",
        "es_retrieved_documents_train_stemmed_path = 'data/es_retrieved_documents_train_stemmed.pickle'\n",
        "es_retrieved_documents_train_unprocessed_path = 'data/es_retrieved_documents_train_unprocessed.pickle'\n",
        "\n",
        "# dev\n",
        "es_retrieved_documents_dev_stemmed_path = 'data/es_retrieved_documents_dev_stemmed.pickle'\n",
        "es_retrieved_documents_dev_unprocessed_path = 'data/es_retrieved_documents_dev_unprocessed.pickle'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dy3cTW2JCU4"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMAnXWfEb-w0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06b9c63-631a-4d31-90c4-4276400db0d4"
      },
      "source": [
        "questions_data_train_stemmed = {}\n",
        "questions_data_train_unprocessed = {}\n",
        "\n",
        "with open(questions_train_medqa_path, 'r') as file:\n",
        "    for idx, line in enumerate(file):\n",
        "        questions_data_train_stemmed[f\"q{idx}\"] = json.loads(line)\n",
        "\n",
        "preprocess_questions(questions_data_train_stemmed, False, True, False, True)\n",
        "\n",
        "with open(questions_train_medqa_path, 'r') as file:\n",
        "    for idx, line in enumerate(file):\n",
        "        questions_data_train_unprocessed[f\"q{idx}\"] = json.loads(line)\n",
        "\n",
        "preprocess_questions(questions_data_train_unprocessed, False, False, False, True)\n",
        "\n",
        "es_retrieved_documents_train_stemmed = load_pickle(es_retrieved_documents_train_stemmed_path)        \n",
        "es_retrieved_documents_train_unprocessed = load_pickle(es_retrieved_documents_train_unprocessed_path)        "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10178/10178 [01:18<00:00, 130.23it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10178/10178 [00:00<00:00, 52567.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JVJHZHuI-QI"
      },
      "source": [
        "### Dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVatdq7XI5Ze",
        "outputId": "77490bec-b3e1-4510-f132-5a194b04fa00"
      },
      "source": [
        "questions_data_dev_stemmed = {}\n",
        "questions_data_dev_unprocessed = {}\n",
        "\n",
        "with open(questions_dev_medqa_path, 'r') as file:\n",
        "    for idx, line in enumerate(file):\n",
        "        questions_data_dev_stemmed[f\"q{idx}\"] = json.loads(line)\n",
        "\n",
        "preprocess_questions(questions_data_dev_stemmed, False, True, False, True)\n",
        "\n",
        "with open(questions_dev_medqa_path, 'r') as file:\n",
        "    for idx, line in enumerate(file):\n",
        "        questions_data_dev_unprocessed[f\"q{idx}\"] = json.loads(line)\n",
        "\n",
        "preprocess_questions(questions_data_dev_unprocessed, False, False, False, True)\n",
        "\n",
        "es_retrieved_documents_dev_stemmed = load_pickle(es_retrieved_documents_dev_stemmed_path)        \n",
        "es_retrieved_documents_dev_unprocessed = load_pickle(es_retrieved_documents_dev_unprocessed_path)        "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1272/1272 [00:09<00:00, 133.29it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1272/1272 [00:00<00:00, 56641.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW89F4pn5HKV",
        "outputId": "1b9e19b6-b562-4483-8bfe-5f0c3f84d0a8"
      },
      "source": [
        "# sanity check\n",
        "es_retrieved_documents_dev_unprocessed[\"q0\"]['question'] == questions_data_dev_unprocessed['q0']['question']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQfADV9qsTVF",
        "outputId": "b0040488-8417-4a8e-8126-74e961117907"
      },
      "source": [
        "questions_data_train_stemmed = {}\n",
        "questions_data_train_unprocessed = {}\n",
        "\n",
        "with open(questions_train_medqa_path, 'r') as file:\n",
        "    for idx, line in enumerate(file):\n",
        "        questions_data_train_stemmed[f\"q{idx}\"] = json.loads(line)\n",
        "\n",
        "preprocess_questions(questions_data_train_stemmed, False, True, False, True)\n",
        "\n",
        "with open(questions_train_medqa_path, 'r') as file:\n",
        "    for idx, line in enumerate(file):\n",
        "        questions_data_train_unprocessed[f\"q{idx}\"] = json.loads(line)\n",
        "\n",
        "preprocess_questions(questions_data_train_unprocessed, False, False, False, True)\n",
        "\n",
        "es_retrieved_documents_train_stemmed = load_pickle(es_retrieved_documents_train_stemmed_path)        \n",
        "es_retrieved_documents_train_unprocessed = load_pickle(es_retrieved_documents_train_unprocessed_path)        "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10178/10178 [01:16<00:00, 132.72it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10178/10178 [00:00<00:00, 52933.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P27aZsZ7sfEv",
        "outputId": "e326e687-1448-4195-99f5-257c05b78f60"
      },
      "source": [
        "# sanity check\n",
        "es_retrieved_documents_train_unprocessed[\"q0\"]['question'] == questions_data_train_unprocessed['q0']['question']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgC-63OcqCJL"
      },
      "source": [
        "## Model definition and freezing layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YKW7BEHsQ0z",
        "outputId": "b7a7cce0-cba9-425b-ed76-10e0158a58e2"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "class CustomBERT(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERT, self).__init__()\n",
        "          self.bert = AutoModel.from_pretrained('bert-base-cased') \n",
        "          self.linear = torch.nn.Linear(self.bert.pooler.dense.out_features, 1)\n",
        "          self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "          # equivalent of having self.bert(**inputs)\n",
        "          # bert_output = self.bert(input_ids=input_ids, \n",
        "          #                         attention_mask=attention_mask, \n",
        "          #                         token_type_ids=token_type_ids)\n",
        "          # linear_output = self.linear(bert_output.last_hidden_state[0][0])\n",
        "\n",
        "\n",
        "          # TODO: return for each batch the output, not only for the one\n",
        "          # reference: https://github.com/huggingface/transformers/pull/96/files\n",
        "          # line 929 in pytorch_pretrained_bert/modeling.py\n",
        "          # also: https://discuss.pytorch.org/t/solved-batching-process-of-torch-nn-linear/15986\n",
        "          bert_output = self.bert(input_ids=input_ids, \n",
        "                                  attention_mask=attention_mask, \n",
        "                                  token_type_ids=token_type_ids)\n",
        "          # TODO: add dropout          \n",
        "          linear_output = self.linear(bert_output.pooler_output)\n",
        "          return linear_output\n",
        "\n",
        "model = CustomBERT().to(device)\n",
        "model.cuda()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-7xDjrsWQWO"
      },
      "source": [
        "layers_to_not_freeze = ['linear', 'pooler'] # freezing first 11 layers\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  if not any(x in name for x in layers_to_not_freeze):\n",
        "    param.requires_grad = False\n",
        "    # print(f\"Set flag to {param.requires_grad} for {name}\")"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkilZEI99J5U"
      },
      "source": [
        "## Queries tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90a4Vi0TGsXV"
      },
      "source": [
        "def create_tokenized_input(questions_dict: dict, documents_collection_dict: dict):\n",
        "  input_queries = []\n",
        "  input_answers = []\n",
        "  input_answers_idx = []\n",
        "\n",
        "  for question_id, question_data in tqdm(questions_dict.items()):\n",
        "    question = question_data['question']\n",
        "    metamap_phrases = question_data['metamap_phrases']\n",
        "    queries = []\n",
        "    for option in question_data['options'].values():\n",
        "      qa = ' '.join(metamap_phrases) + ' ' + option\n",
        "      retrieved_documents = get_context(question_id=question_id, \n",
        "                                        option=option, \n",
        "                                        documents_collection=documents_collection_dict) \n",
        "      context = ' '.join(retrieved_documents)\n",
        "      query = tokenizer(context, qa, \n",
        "                        add_special_tokens=True,\n",
        "                        max_length = 512, \n",
        "                        padding='max_length',\n",
        "                        truncation=True,\n",
        "                        return_tensors=\"pt\"\n",
        "                        )\n",
        "      query_input_ids = query[\"input_ids\"].flatten()\n",
        "      query_token_type_ids = query[\"token_type_ids\"].flatten()\n",
        "      query_attention_mask = query[\"attention_mask\"].flatten()\n",
        "\n",
        "      queries.append({\n",
        "          \"input_ids\": query_input_ids,\n",
        "          \"token_type_ids\": query_token_type_ids,\n",
        "          \"attention_mask\": query_attention_mask\n",
        "      })\n",
        "    # break\n",
        "    # dev_dataset_input.append({\n",
        "    #       \"correct_answer\": question_data[\"answer\"],\n",
        "    #       \"correct_answer_idx\": letter_answer_to_index(question_data['answer_idx']),\n",
        "    #       \"queries\": queries\n",
        "    #   })\n",
        "    input_queries.append(queries)\n",
        "    input_answers.append(question_data[\"answer\"])\n",
        "    \n",
        "    input_answers_idx.append(letter_answer_to_index(question_data['answer_idx']))\n",
        "  return input_queries, input_answers, input_answers_idx"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFx8Gh7_BkA8",
        "outputId": "79e08ac5-6546-472c-fb16-1ce67af2d8db"
      },
      "source": [
        "train_input_queries, train_input_answers, train_input_answers_idx = create_tokenized_input(questions_dict=questions_data_train_unprocessed,\n",
        "                                                                                     documents_collection_dict=es_retrieved_documents_train_unprocessed)\n",
        "\n",
        "\n",
        "dev_input_queries, dev_input_answers, dev_input_answers_idx = create_tokenized_input(questions_dict=questions_data_dev_unprocessed,\n",
        "                                                                                     documents_collection_dict=es_retrieved_documents_dev_unprocessed)\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10178/10178 [01:56<00:00, 87.00it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1272/1272 [00:15<00:00, 80.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfBu2t5d9Ojd"
      },
      "source": [
        "## DataLoader creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWa5K1MfF7Ie"
      },
      "source": [
        "### MedQA dataset definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7VPeVlMF9ou"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, SequentialSampler, TensorDataset\n",
        "\n",
        "class MedQADataset(TensorDataset):\n",
        "  def __init__(self, all_possible_queries, answers, answers_idx):\n",
        "        self.all_possible_queries = all_possible_queries\n",
        "        self.answers = answers\n",
        "        self.answers_idx = answers_idx\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.all_possible_queries)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        queries = self.all_possible_queries[index]\n",
        "        correct_answer = self.answers[index]\n",
        "        correct_answer_idx = self.answers_idx[index]\n",
        "        return queries, correct_answer, correct_answer_idx\n",
        "\n",
        "batch_size = 32"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qti2XFuLF-0w"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axxAQbzgGMYB"
      },
      "source": [
        "train_dataset = MedQADataset(all_possible_queries=train_input_queries, \n",
        "                             answers=train_input_answers, \n",
        "                             answers_idx=train_input_answers_idx)\n",
        " \n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              sampler = SequentialSampler(train_dataset), \n",
        "                              batch_size = batch_size)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65dgYcmyGC75"
      },
      "source": [
        "### Dev dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBwdF6Ya8o7D"
      },
      "source": [
        "dev_dataset = MedQADataset(all_possible_queries=dev_input_queries, \n",
        "                           answers=dev_input_answers, \n",
        "                           answers_idx=dev_input_answers_idx)\n",
        " \n",
        "dev_dataloader = DataLoader(dataset=dev_dataset, \n",
        "                            sampler = SequentialSampler(dev_dataset), \n",
        "                            batch_size = batch_size)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiA1NMf5LzKb"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "total_t0 = time.time()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2XxaCul9Re-"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_jzsCxDRXQx"
      },
      "source": [
        "x_output = x_output.detach().cpu().numpy()\n",
        "x_answers = x_answers.to('cpu').numpy()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QabnI89wwuTL",
        "outputId": "e65b9d24-4f25-4645-9b8a-7a4e15aaca0d"
      },
      "source": [
        "calculate_accuracy(x_output, x_answers)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDb0yjE6OaJB"
      },
      "source": [
        "def calculate_accuracy(predictions_distribution, correct_answers):\n",
        "  predictions = np.argmax(predictions_distribution, axis=1)\n",
        "  return np.sum(np.argmax(x_output, axis=1) == x_answers) / len(correct_answers)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_F63zPe_S4LT",
        "outputId": "f897e768-ad15-452e-e138-a347979b43e7"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "#  We fine-tune for 3 epochs with a learning rate of 5e-5 and a batch size of 32\n",
        "num_epochs = 2\n",
        "lr = 5e-5\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "total_steps = num_epochs * batch_size\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'======== Epoch {epoch + 1} / {num_epochs} ========')\n",
        "  t0 = time.time()\n",
        "  total_train_loss = 0\n",
        "  model.train()\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    if step % 10 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "      print(f'Batch {step} of {len(train_dataloader)}. Elapsed: {elapsed}')\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    questions_queries_collection = batch[0]\n",
        "    answers = batch[1]\n",
        "    answers_indexes = batch[2]\n",
        "    queries_outputs = []\n",
        "    for question_queries in questions_queries_collection:\n",
        "        input_ids = question_queries[\"input_ids\"].to(device)\n",
        "        input_token_type_ids = question_queries[\"token_type_ids\"].to(device)        \n",
        "        input_attention_mask = question_queries[\"attention_mask\"].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        output = model(input_ids=input_ids, \n",
        "                        attention_mask=input_attention_mask,\n",
        "                        token_type_ids=input_token_type_ids)\n",
        "        queries_outputs.append(output)        \n",
        "    # each row represents values for the same question, each column represents an output for an answer option\n",
        "    queries_outputs = torch.stack(queries_outputs).reshape([5, len(answers)]).transpose(0, 1)\n",
        "    # choosing the indexes of the answers with the highest post-softmax value\n",
        "    output = model.softmax(queries_outputs)\n",
        "\n",
        "    loss = criterion(output, answers_indexes.to(device))\n",
        "    total_train_loss += loss\n",
        "    loss.backward()\n",
        "    # Clip the norm of the gradients to 1.0.\n",
        "    # This is to help prevent the \"exploding gradients\" problem.\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update the learning rate.\n",
        "    scheduler.step()\n",
        "  \n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "  \n",
        "  # Measure how long this epoch took.\n",
        "  training_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "  # ========================================\n",
        "  #               Validation\n",
        "  # ========================================\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  # Put the model in evaluation mode--the dropout layers behave differently\n",
        "  # during evaluation.\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for step, batch in enumerate(dev_dataloader):\n",
        "    questions_queries_collection = batch[0]\n",
        "    answers = batch[1]\n",
        "    answers_indexes = batch[2]\n",
        "\n",
        "    queries_outputs = []\n",
        "    for question_queries in questions_queries_collection:\n",
        "        input_ids = question_queries[\"input_ids\"].to(device)\n",
        "        input_token_type_ids = question_queries[\"token_type_ids\"].to(device)        \n",
        "        input_attention_mask = question_queries[\"attention_mask\"].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        output = model(input_ids=input_ids, \n",
        "                        attention_mask=input_attention_mask,\n",
        "                        token_type_ids=input_token_type_ids)\n",
        "        queries_outputs.append(output)        \n",
        "\n",
        "    queries_outputs = torch.stack(queries_outputs).reshape([5, len(answers)]).transpose(0, 1)\n",
        "    output = model.softmax(queries_outputs)\n",
        "    loss = criterion(output, answers_indexes.to(device))\n",
        "    \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    output = output.detach().cpu().numpy()\n",
        "    answers_indexes = answers_indexes.to('cpu').numpy()\n",
        "\n",
        "    total_eval_accuracy += calculate_accuracy(output, answers_indexes)\n",
        "\n",
        "\n",
        "  # Report the final accuracy for this validation run.\n",
        "  avg_val_accuracy = total_eval_accuracy / len(dev_dataloader)\n",
        "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "  \n",
        "  # Measure how long the validation run took.\n",
        "  validation_time = format_time(time.time() - t0)\n",
        "  \n",
        "  print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "  print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "  # Record all statistics from this epoch.\n",
        "  training_stats.append(\n",
        "      {\n",
        "          'epoch': epoch + 1,\n",
        "          'Training Loss': avg_train_loss,\n",
        "          'Valid. Loss': avg_val_loss,\n",
        "          'Valid. Accur.': avg_val_accuracy,\n",
        "          'Training Time': training_time,\n",
        "          'Validation Time': validation_time\n",
        "      }\n",
        "  )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 2 ========\n",
            "Batch 10 of 319. Elapsed: 0:01:03\n",
            "Batch 20 of 319. Elapsed: 0:02:07\n",
            "Batch 30 of 319. Elapsed: 0:03:12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-72e1384ce4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mqueries_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquestion_queries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions_queries_collection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0minput_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0minput_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzAODV12ZA1h"
      },
      "source": [
        "## Draft section: experimenting with python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrjWHDdjO9Dn",
        "outputId": "76c8a309-4d28-4970-a2ab-b2d8f9207941"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2091, 0.2025, 0.1957, 0.1948, 0.1979],\n",
              "        [0.1837, 0.1944, 0.2211, 0.2106, 0.1902],\n",
              "        [0.2182, 0.1957, 0.1901, 0.1960, 0.2001],\n",
              "        [0.2092, 0.2014, 0.1885, 0.2007, 0.2002],\n",
              "        [0.2030, 0.1914, 0.2045, 0.2073, 0.1937],\n",
              "        [0.1910, 0.2003, 0.1922, 0.2009, 0.2155],\n",
              "        [0.1840, 0.2092, 0.2006, 0.1975, 0.2086],\n",
              "        [0.1979, 0.2019, 0.2062, 0.1933, 0.2007],\n",
              "        [0.2099, 0.1965, 0.2123, 0.1943, 0.1869],\n",
              "        [0.1985, 0.1923, 0.2042, 0.2049, 0.2001],\n",
              "        [0.1968, 0.2112, 0.2066, 0.1919, 0.1936],\n",
              "        [0.2060, 0.1895, 0.2041, 0.1951, 0.2053],\n",
              "        [0.2045, 0.1961, 0.1932, 0.1994, 0.2068],\n",
              "        [0.2029, 0.2034, 0.1962, 0.1895, 0.2081],\n",
              "        [0.2074, 0.2016, 0.2009, 0.1991, 0.1910],\n",
              "        [0.1936, 0.1956, 0.2074, 0.2093, 0.1942],\n",
              "        [0.1827, 0.1978, 0.1970, 0.2142, 0.2084],\n",
              "        [0.2005, 0.2027, 0.1969, 0.2050, 0.1949],\n",
              "        [0.2088, 0.2007, 0.2026, 0.1941, 0.1938],\n",
              "        [0.2012, 0.2046, 0.2078, 0.1994, 0.1871],\n",
              "        [0.1849, 0.1992, 0.1965, 0.2051, 0.2143],\n",
              "        [0.1989, 0.1911, 0.2097, 0.1992, 0.2010],\n",
              "        [0.1881, 0.2187, 0.1909, 0.1917, 0.2106],\n",
              "        [0.1986, 0.1913, 0.2046, 0.2086, 0.1969],\n",
              "        [0.2027, 0.1903, 0.1998, 0.1996, 0.2077],\n",
              "        [0.2055, 0.1873, 0.1996, 0.1971, 0.2106],\n",
              "        [0.1922, 0.2036, 0.1915, 0.1996, 0.2131],\n",
              "        [0.2000, 0.2003, 0.2081, 0.1962, 0.1953],\n",
              "        [0.1952, 0.1939, 0.2032, 0.2124, 0.1953],\n",
              "        [0.2123, 0.1962, 0.2056, 0.1966, 0.1893],\n",
              "        [0.2010, 0.1966, 0.2040, 0.1921, 0.2063],\n",
              "        [0.2008, 0.2013, 0.1943, 0.1956, 0.2079]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OC7JW8yO7FU",
        "outputId": "04d03abc-f62b-4693-984c-aa5ef9f69bd1"
      },
      "source": [
        "x_answers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 0, 4, 2, 0, 2, 4, 2, 0, 0, 0, 3, 1, 0, 1, 4, 2, 0, 1, 1, 3, 3, 0, 3,\n",
              "        2, 3, 0, 3, 4, 3, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joIAD8BpOVhk",
        "outputId": "ddd1bfa5-5985-4db3-9cc0-6553a9918fd4"
      },
      "source": [
        "criterion(x_output, x_answers.to(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yE5fK51PLqd",
        "outputId": "732f9343-2d28-4772-d06a-08eb0be4b7f1"
      },
      "source": [
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "\n",
        "print(input)\n",
        "print(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4740,  0.1978,  1.1561,  0.3965, -2.4661],\n",
            "        [ 0.3623,  0.3765, -0.1808,  0.3930,  0.4327],\n",
            "        [-1.3627,  1.3564,  0.6688, -0.7077, -0.3267]], requires_grad=True)\n",
            "tensor([3, 4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIu7bSKfPLIE"
      },
      "source": [
        "aaa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63QcmfQqXRrQ",
        "outputId": "f3a072a6-48a0-4467-a558-b1f23826c24e"
      },
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "loss(x, y.cuda())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6028, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_HQAlg1VIun",
        "outputId": "628048c5-211e-4759-a8ea-bd57a4335f99"
      },
      "source": [
        "torch.argmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 4], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzCwzcOaJ9QY",
        "outputId": "1e9e5134-dfd9-4da9-9a8b-e60ac2e92653"
      },
      "source": [
        "softmax(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2183, 0.1914, 0.1919, 0.2114, 0.1871],\n",
              "        [0.1942, 0.2024, 0.2090, 0.2019, 0.1925],\n",
              "        [0.2004, 0.2083, 0.1953, 0.1815, 0.2146]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7dqLsGQRVzs",
        "outputId": "d26be0af-c3e4-4cd0-e1dd-8ed8f0d34cf7"
      },
      "source": [
        "softmax = torch.nn.Softmax(dim=1)\n",
        "sum(softmax(x)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YACAT0DwUdMu",
        "outputId": "b57fa3a2-b7a1-4628-f9d6-e8c5e28898ff"
      },
      "source": [
        "y.reshape([5, 3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2480, 0.0207, 0.1035],\n",
              "        [0.1167, 0.0618, 0.1424],\n",
              "        [0.1192, 0.0939, 0.0778],\n",
              "        [0.2159, 0.0595, 0.0044],\n",
              "        [0.0940, 0.0116, 0.1723]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIxc7CvRUiPz",
        "outputId": "89f92aa0-0576-4a90-c6da-0d9449274fdd"
      },
      "source": [
        "y.reshape([5, 3]).transpose(0, 1)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2480, 0.1167, 0.1192, 0.2159, 0.0940], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGEcT3NMG8yY",
        "outputId": "521e0dfc-ceba-4906-e686-50d160b8e33c"
      },
      "source": [
        "softmax = torch.nn.Softmax(dim=1)\n",
        "res = softmax(y.reshape([5, 3]))\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3756, 0.2993, 0.3251],\n",
            "        [0.3364, 0.3184, 0.3452],\n",
            "        [0.3408, 0.3323, 0.3270],\n",
            "        [0.3753, 0.3210, 0.3038],\n",
            "        [0.3331, 0.3067, 0.3602]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vznhhb2QUB1p",
        "outputId": "362e772e-d62d-41aa-9f62-d9be312d39c8"
      },
      "source": [
        "res[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2183, 0.1942, 0.2004], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "HPNjI8y88ovC",
        "outputId": "4461dacd-1953-47b7-d83d-92322f845868"
      },
      "source": [
        "# train_dataloader = DataLoader(\n",
        "#             train_dataset,  # The training samples.\n",
        "#             sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "#             batch_size = batch_size # Trains with this batch size.\n",
        "#         )\n",
        "\n",
        "# # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "# validation_dataloader = DataLoader(\n",
        "#             val_dataset, # The validation samples.\n",
        "#             sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "#             batch_size = batch_size # Evaluate with this batch size.\n",
        "#         )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f9de62122017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkR0e96m8oPu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z8aechJdCPe"
      },
      "source": [
        "example_query = \"21-year-old sexually active male fever pain urination inflammation pain in the right knee culture joint bacteria not ferment maltose polysaccharide capsule physician orders antibiotic therapy patient mechanism of action medication given blocks cell wall synthesis following given\"\n",
        "example_top_n_documents = [{'score': 42.14371,\n",
        "  'evidence': {'name': 'Biochemistry_Lippincott.txt0',\n",
        "   'content': '2.2. a 42-year-old male patient undergoing radiation therapy for prostate cancer develops severe pain in the metatarsal phalangeal joint of his right big toe.'}},\n",
        " {'score': 40.0278,\n",
        "  'evidence': {'name': 'First_Aid_Step2.txt0',\n",
        "   'content': 'an active 13-year-old boy has anterior knee pain.'}},\n",
        " {'score': 34.522305,\n",
        "  'evidence': {'name': 'Anatomy_Gray.txt0',\n",
        "   'content': 'a 45-year-old man came to his physician complaining of pain and weakness in his right shoulder.'}},\n",
        " {'score': 33.678368,\n",
        "  'evidence': {'name': 'InternalMed_Harrison.txt0',\n",
        "   'content': 'perihepatitis should be suspected in young, sexually active women who develop right-upper-quadrant pain, fever, or nausea.'}},\n",
        " {'score': 32.35567,\n",
        "  'evidence': {'name': 'Biochemistry_Lippincott.txt0',\n",
        "   'content': 'case 7: joint pain\\n\\npatient presentation: ir is a 22-year-old male who presents for follow-up 10 days after having been treated in the emergency department (ed) for severe inflammation at the base of his thumb.'}},\n",
        " {'score': 32.258705,\n",
        "  'evidence': {'name': 'InternalMed_Harrison.txt0',\n",
        "   'content': 'interferon Î³ was successful in the treatment of a 3-year-old boy with prolonged fever, abdominal pain, and thrombocytopenia due to\\n\\nc. burnetii that had not been eradicated with conventional antibiotic therapy.'}},\n",
        " {'score': 30.173576,\n",
        "  'evidence': {'name': 'InternalMed_Harrison.txt0',\n",
        "   'content': 'the azolesâ€™ mechanism of action is inhibition of ergosterol synthesis in the fungal cell wall.'}},\n",
        " {'score': 29.039585,\n",
        "  'evidence': {'name': 'InternalMed_Harrison.txt0',\n",
        "   'content': 'a 45-year-old woman receiving high-dose glucocorticoids developed right hip pain.'}},\n",
        " {'score': 28.646845,\n",
        "  'evidence': {'name': 'InternalMed_Harrison.txt0',\n",
        "   'content': 'in common with other gram-positive bacteria, pneumococci have a cell membrane beneath a cell wall, which in turn is covered by a polysaccharide capsule.'}},\n",
        " {'score': 28.138422,\n",
        "  'evidence': {'name': 'Pharmacology_Katzung.txt0',\n",
        "   'content': 'see chapter 52.\\n\\nantagonize the action of bactericidal cell wall-active agents because cell wall-active agents require that the bacteria be actively growing and dividing.'}}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "cde4de5a21294e889901528cafac5f03",
            "98714877c70341ec8e50b62739af9d83",
            "9a23bdb1a69845c596ed35a6d94a28d4",
            "f4dc7ec89bd941f8aa5c51a25b922612",
            "8c8f617db98a426fbfdd9c6fede753ff",
            "5de33aeb3040479c938bfa1658eebf56",
            "7358d1e4f7184a8eb50a93f92aece226",
            "4598b192c96247488d8bb350dad9313d",
            "0d73ecc29deb4ff79cd24a29df801832",
            "8fe0738b1f284dada35965a4f6c49791",
            "38ee25918b3f4011bef5ffd40ee55858",
            "dbba11aa124f44e297d2c89685326c21",
            "c70b7c3dc9d8449099f6dabe5a5af32c",
            "55797d11c5f94fcba4c9caf6dc000626",
            "87be7e2ceec94391b1c258b53362cc8c",
            "48cd4ac2b73c44bd8a9ad9e7e66f7956",
            "307bbf959845492aaca909a78ecc370f",
            "310634794a0f47a6b933cb1f599fc515",
            "18ee8816e8624988bf51635b5d11d48d",
            "357d723d2b69477c92ee117fb379f604",
            "0bd15e13fba44157abd7cbe6e9ea2779",
            "48413323a1b941e784ad501069cb60a1",
            "abedf67f54c846a4928e9700e9d57e06",
            "eff86a8f22634b15b4800622e8713da7",
            "cd6c371361684ab08dbb63688d59c69a",
            "68dc7c2035394f4db7107e55f5605495",
            "4ecfdbb41c7e4074a0da0ceccdf5074b",
            "471de2bea25a43dda3f9d55f3fed0c62",
            "eb0ccbfd5c5c49f2a62f57a016600e47",
            "1f80cf9f737242c3bd2a8585623da3fc",
            "b24dadbb8c794e1bb7bb6063f28d49a1",
            "f882ca9fb9d44d5dac6e60bee9f1af0c",
            "918e8de71eb94b698def2492c634c5ba",
            "68aea9ca8e9c44c4bece2875eb2255d5",
            "9de9b2befbed4cc491679517123adf22",
            "d2ca6202b0fe4ff0aa3adc48900ac643",
            "165cd6ac16c546af9ceb1e15d5346703",
            "420e533886a1408989e1b92dc69ae16f",
            "7040af81148e4bb19ad2065007582db3",
            "a0ce8f7fb1a24285b47d2e32e37f4d43"
          ]
        },
        "id": "C6rou2xGjoel",
        "outputId": "2ab19794-6409-42a0-ad07-19fcd9475f44"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = AutoModel.from_pretrained('bert-base-cased')\n",
        "# model_qa = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
        "# model_multiple = AutoModelForMultipleChoice.from_pretrained('bert-base-cased')\n",
        "# Displaying the information about the particular layer's weights\n",
        "# model_multiple.bert.encoder.layer[0].attention.self.query.weight\n",
        "# model.encoder.layer[0].attention.self.query.weight == model_multiple.bert.encoder.layer[0].attention.self.query.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cde4de5a21294e889901528cafac5f03",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d73ecc29deb4ff79cd24a29df801832",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "307bbf959845492aaca909a78ecc370f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd6c371361684ab08dbb63688d59c69a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "918e8de71eb94b698def2492c634c5ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWNH_1A-n3Ay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "247277de237d485d8e4abd8f15bdac2e",
            "811471e906194f6491efac2a9a99e1ad",
            "4a48a44a15db493ca022a40561a1d525",
            "bb78d0cd74a44b9390dc4407f49a846a",
            "33f3b85c42414aba8961297f8ccffc4e",
            "0d4668a9a64240a4ad89a493aa4f3720",
            "58572fef9e0943b4a9e469831713dbc5",
            "630383a016a544528155f82eb0b3f0a7",
            "875402f45fe348888a55ea790dc1e99f",
            "9b0ee37219c3405388c34c71a1d325a5",
            "14a087594557474bb67dcf271f06153b",
            "58667c0f75c04be790059be8d85892da",
            "ee71d40cfc7a44a490f1b67fde6d926e",
            "ceeabe6a14664060ac68687ecf7cc802",
            "e92c12560d134bd8b8bbf10843d18f42",
            "dddbb4d2d1884a6a9263fb54287ef0af"
          ]
        },
        "id": "wOyj6nT4-pVB",
        "outputId": "4999cb12-c6ef-4d88-cb35-5b028a8f5ebf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "247277de237d485d8e4abd8f15bdac2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "875402f45fe348888a55ea790dc1e99f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Hq2DN5HjTw"
      },
      "source": [
        "bert_base_uncased = AutoModel.from_pretrained('bert-base-cased') \n",
        "text = r\"\"\"\n",
        "ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
        "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
        "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
        "TensorFlow 2.0 and PyTorch. If the previous second dimension of the output was 125 i wonder what will be the new one\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "             {\n",
        "                 \"question\": \"21-year-old sexually active male fever pain urination inflammation pain in the right knee culture joint bacteria not ferment maltose polysaccharide capsule physician orders antibiotic therapy patient mechanism of action medication given blocks cell wall synthesis following given\",\n",
        "                 \"options\": {\n",
        "                     \"A\": \"chloramphenicol\",\n",
        "                     \"B\": \"centamicin\",\n",
        "                     \"C\": \"ciprofloxacin\",\n",
        "                     \"D\": \"ceftriaxone\",\n",
        "                     \"E\": \"trimethoprim\"\n",
        "                 },\n",
        "                  \"correct_answer\": \"A\"\n",
        "             }\n",
        "            #  {\n",
        "            #      \"question\": \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
        "            #     \"options\": {\n",
        "            #         \"A\": \"over 20\",\n",
        "            #         \"B\": \"over 30\",\n",
        "            #         \"C\": \"less than 20\",\n",
        "            #         \"D\": \"less than 30\"\n",
        "            #     },\n",
        "            #     \"correct_answer\": \"B\"\n",
        "            #  }\n",
        "\n",
        "    #  \"What does ðŸ¤— Transformers provide?\",\n",
        "    #  \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0ReJI2vLLxg",
        "outputId": "c520281b-6adf-4420-d490-09ab567262d3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ByvZD4qZw7E"
      },
      "source": [
        "text = r\"\"\"\n",
        "ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
        "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
        "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
        "TensorFlow 2.0 and PyTorch.\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "             {\n",
        "                 \"question\": \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
        "                \"options\": {\n",
        "                    \"A\": \"over 20\",\n",
        "                    \"B\": \"over 32+\",\n",
        "                    \"C\": \"less than 20\",\n",
        "                    \"D\": \"less than 30\"\n",
        "                }\n",
        "             },\n",
        "             {\n",
        "             \"question\": \"What does ðŸ¤— Transformers provide?\",\n",
        "                \"options\": {\n",
        "                    \"A\": \"deep learning magic\", \n",
        "                    \"B\": \"general - purpose architectures\", \n",
        "                    \"C\": \"general knowledge\", \n",
        "                    \"D\": \"nothing in general\"\n",
        "                }\n",
        "             }\n",
        "\n",
        "    #  \"What does ðŸ¤— Transformers provide?\",\n",
        "    #  \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0YJ2Rj5FD73",
        "outputId": "9fa64774-ca8b-48aa-b94f-a487648be74c"
      },
      "source": [
        "x1 = torch.Tensor([1, 2])\n",
        "x2 = torch.Tensor([1, 2])\n",
        "xs = [x1, x2]\n",
        "\n",
        "y = torch.cat(xs, dim=0)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 1., 2.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "acua_zvu-ojz",
        "outputId": "0878420d-82ac-489f-d5d6-00e5e86f1983"
      },
      "source": [
        "for question_option in questions:\n",
        "    question = question_option[\"question\"]\n",
        "    print(question)\n",
        "    answer_outputs = []\n",
        "    for answer in question_option['options'].values():\n",
        "        qa = question + ' ' + answer\n",
        "        \n",
        "        input = tokenizer(text, qa, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "    # print(tokenizer.decode(input_ids))\n",
        "        input_ids = input[\"input_ids\"]\n",
        "        input_token_type_ids = input[\"token_type_ids\"]\n",
        "        input_attention_mask = input[\"attention_mask\"]\n",
        "        \n",
        "        output = model(input_ids=input_ids, \n",
        "                        attention_mask=input_attention_mask,\n",
        "                        token_type_ids=input_token_type_ids)\n",
        "        answer_outputs.append(output)\n",
        "\n",
        "    answer_probs = model.softmax(torch.FloatTensor(answer_outputs))\n",
        "    chosen_answer_idx = torch.argmax(answer_probs).item()\n",
        "    \n",
        "    print(chosen_answer_idx)\n",
        "    # print(torch.eq(outputs.last_hidden_state, outputs2.last_hidden_state))\n",
        "    # print(torch.eq(outputs, outputs2))\n",
        "    # print(type(outputs))\n",
        "    # print(outputs)\n",
        "    # answer_start_scores = outputs.start_logits\n",
        "    # answer_end_scores = outputs.end_logits\n",
        "    # answer_start = torch.argmax(\n",
        "    #     answer_start_scores\n",
        "    # )  # Get the most likely beginning of answer with the argmax of the score\n",
        "    # answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "    # answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "    # print(f\"Question: {question}\")\n",
        "    # print(f\"Answer: {answer}\")\n",
        "# Question: How many pretrained models are available in ðŸ¤— Transformers?\n",
        "# Answer: over 32 +\n",
        "# Question: What does ðŸ¤— Transformers provide?\n",
        "# Answer: general - purpose architectures\n",
        "# Question: ðŸ¤— Transformers provides interoperability between which frameworks?\n",
        "# Answer: tensorflow 2 . 0 and pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How many pretrained models are available in ðŸ¤— Transformers?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-82a09263b429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# input_ids = inputs[\"input_ids\"].tolist()[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBlFb-7Oa_Ph",
        "outputId": "81faede6-a9e4-4957-8c60-4629fe91067f"
      },
      "source": [
        "answer_outputs\n",
        "# answer_outputs[0].detach().numpy()[0]\n",
        "# import torch.nn.functional as F\n",
        "# answer_outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0.4984], device='cuda:0', grad_fn=<AddBackward0>),\n",
              " tensor([0.5120], device='cuda:0', grad_fn=<AddBackward0>),\n",
              " tensor([0.4534], device='cuda:0', grad_fn=<AddBackward0>),\n",
              " tensor([0.3959], device='cuda:0', grad_fn=<AddBackward0>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euZJ1fsFgyuF",
        "outputId": "5fc83bce-0d06-43bd-8c9e-155584b4020d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.3450, -0.4074, -0.3031, -0.3128])\n",
            "tensor([0.2491, 0.2340, 0.2597, 0.2572])\n",
            "tensor(2)\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "DJHkMeDPe4NU",
        "outputId": "a64107a5-bf02-44e9-d0f6-695ef85e7b9e"
      },
      "source": [
        "x(answer_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-90dc192cc9bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'softmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCVcF9MfbdZ6",
        "outputId": "34998580-d719-47c8-f496-af7b32df14c7"
      },
      "source": [
        "\n",
        "data = torch.randn(5)\n",
        "print(data)\n",
        "print(F.softmax(data, dim=0))\n",
        "print(F.softmax(data, dim=0).sum())  # Sums to 1 because it is a distribution!\n",
        "print(F.log_softmax(data, dim=0))  # theres also log_softmax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.4314, -1.4257,  1.5849, -0.7597,  1.6632])\n",
            "tensor([0.1241, 0.0194, 0.3934, 0.0377, 0.4254])\n",
            "tensor(1.)\n",
            "tensor([-2.0865, -3.9436, -0.9330, -3.2776, -0.8547])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXFa7OESeRDQ",
        "outputId": "979dbded-47e4-4d4e-f7d9-d1b850469465"
      },
      "source": [
        "answer_outputs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2288], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmx6ke7WcG91",
        "outputId": "f5bf5a20-2722-4b82-dfe1-47713a567d69"
      },
      "source": [
        "torch.unsqueeze(answer_outputs[0], dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2288]], grad_fn=<UnsqueezeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwT-b4p-c7hT",
        "outputId": "f4c8c870-246a-44e8-be2f-96ed5ebdd84f"
      },
      "source": [
        "test = torch.FloatTensor([1,2,3])\n",
        "x(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0900, 0.2447, 0.6652])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "aCPFAABGa0_j",
        "outputId": "ca3d517a-d269-4263-8ee8-39061ae0b2b3"
      },
      "source": [
        "\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=1)\n",
        "softmax(answer_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b60a2700c54a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'softmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "URl4Y_a7_-tP",
        "outputId": "cd57f1e6-f044-4431-8012-943f1895fd7c"
      },
      "source": [
        "c = \"This would be text from the MedQA paper retrieved. Probably by using the IR system from MedQA first.\"\n",
        "qa = \"This is the question, right? Here is the answer\"\n",
        "\n",
        "test_input = tokenizer(c, qa, add_special_tokens=True, return_tensors=\"pt\")\n",
        "test_input_ids = test_input['input_ids'].tolist()[0]\n",
        "\n",
        "# test_outputs = model(**test_input)\n",
        "# print(type(test_outputs))\n",
        "# print(test_outputs.last_hidden_state.shape)\n",
        "# print(test_outputs.last_hidden_state)\n",
        "\n",
        "\n",
        "test_output_multiple = model_multiple(**test_input)\n",
        "\n",
        "# print(type(test_output_multiple))\n",
        "# print(test_outputs.last_hidden_state.shape)\n",
        "# print(test_outputs.last_hidden_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2d50a8319f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_output_multiple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(type(test_output_multiple))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_multiple' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZhq1FIFqVd-",
        "outputId": "7a8cc7a1-92ee-4875-f180-3b7e04ad18ca"
      },
      "source": [
        "text = r\"\"\"\n",
        "ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
        "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
        "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
        "TensorFlow 2.0 and PyTorch.\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "             {\n",
        "                 \"question\": \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
        "                \"options\": {\n",
        "                    \"A\": \"over 20\",\n",
        "                    \"B\": \"over 30\",\n",
        "                    \"C\": \"less than 20\",\n",
        "                    \"D\": \"less than 30\"\n",
        "                },\n",
        "                \"correct_answer\": \"B\"\n",
        "             }\n",
        "\n",
        "    #  \"What does ðŸ¤— Transformers provide?\",\n",
        "    #  \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
        "]\n",
        "\n",
        "for question_option in questions:\n",
        "    question = question_option[\"question\"]\n",
        "\n",
        "    inputs = tokenizer(question, text, \n",
        "                       add_special_tokens=True,\n",
        "                       return_tensors=\"pt\"\n",
        "                       )\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "    outputs = model(**inputs)\n",
        "    print(type(input_ids))\n",
        "    print(tokenizer.decode(input_ids))\n",
        "    # answer_start_scores = outputs.start_logits\n",
        "    # answer_end_scores = outputs.end_logits\n",
        "    # answer_start = torch.argmax(\n",
        "    #     answer_start_scores\n",
        "    # )  # Get the most likely beginning of answer with the argmax of the score\n",
        "    # answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "    # answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "    # print(f\"Question: {question}\")\n",
        "    # print(f\"Answer: {answer}\")\n",
        "# Question: How many pretrained models are available in ðŸ¤— Transformers?\n",
        "# Answer: over 32 +\n",
        "# Question: What does ðŸ¤— Transformers provide?\n",
        "# Answer: general - purpose architectures\n",
        "# Question: ðŸ¤— Transformers provides interoperability between which frameworks?\n",
        "# Answer: tensorflow 2 . 0 and pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[CLS] How many pretrained models are available in [UNK] Transformers? [SEP] [UNK] Transformers ( formerly known as pytorch - transformers and pytorch - pretrained - bert ) provides general - purpose architectures ( BERT, GPT - 2, RoBERTa, XLM, DistilBert, XLNet â€¦ ) for Natural Language Understanding ( NLU ) and Natural Language Generation ( NLG ) with over 32 + pretrained models in 100 + languages and deep interoperability between TensorFlow 2. 0 and PyTorch. [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g4MhFNUcfKJ",
        "outputId": "8921e7cb-709c-4714-a2a5-daa3590aa782"
      },
      "source": [
        "text = r\"\"\"\n",
        "ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
        "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
        "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
        "TensorFlow 2.0 and PyTorch.\n",
        "\"\"\"\n",
        "\n",
        "questions = {\n",
        "     \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
        "     \"What does ðŸ¤— Transformers provide?\",\n",
        "     \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
        "}\n",
        "\n",
        "for question in questions:\n",
        "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "    outputs = model(**inputs)\n",
        "    print(outputs.to_tuple())\n",
        "    break\n",
        "    # answer_start_scores = outputs.start_logits\n",
        "    # answer_end_scores = outputs.end_logits\n",
        "    # answer_start = torch.argmax(\n",
        "    #     answer_start_scores\n",
        "    # )  # Get the most likely beginning of answer with the argmax of the score\n",
        "    # answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "    # answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "    # print(f\"Question: {question}\")\n",
        "    # print(f\"Answer: {answer}\")\n",
        "# Question: How many pretrained models are available in ðŸ¤— Transformers?\n",
        "# Answer: over 32 +\n",
        "# Question: What does ðŸ¤— Transformers provide?\n",
        "# Answer: general - purpose architectures\n",
        "# Question: ðŸ¤— Transformers provides interoperability between which frameworks?\n",
        "# Answer: tensorflow 2 . 0 and pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[ 0.3589, -0.0604, -0.5795,  ...,  0.0564,  0.6875,  0.4772],\n",
            "         [ 0.7745, -0.5458,  0.7483,  ..., -0.3884, -0.1324,  0.0269],\n",
            "         [ 0.3030,  0.1737,  0.1765,  ...,  0.6794,  0.1231,  0.1231],\n",
            "         ...,\n",
            "         [-0.1903, -0.0120,  0.4077,  ...,  0.2297, -0.3722, -0.2795],\n",
            "         [ 0.9130, -0.2462, -0.2226,  ...,  0.8263, -0.1436, -0.2555],\n",
            "         [ 0.9229, -0.2293, -0.1734,  ...,  0.8629, -0.1519, -0.2260]]],\n",
            "       grad_fn=<NativeLayerNormBackward>), tensor([[-0.9746,  0.9100,  1.0000, -0.9990,  0.9973, -0.9963,  0.9998,  0.9964,\n",
            "         -0.9986, -0.9374,  0.9994,  0.9993,  0.9973, -1.0000, -0.9992, -0.9989,\n",
            "          0.9992, -0.9526, -1.0000,  0.9767,  0.8413, -1.0000,  0.8745, -0.9826,\n",
            "          0.9988,  0.0665,  0.9989,  1.0000,  0.9918,  0.9543,  0.8465, -0.9987,\n",
            "         -0.9928, -0.9999,  0.8127, -0.8492, -0.9865, -0.8104, -0.9817,  0.9884,\n",
            "         -0.9820,  0.9928, -0.9175, -0.9273, -0.9886,  0.8496,  0.8637, -0.1282,\n",
            "         -0.8642,  1.0000, -0.9996,  1.0000,  0.9958,  1.0000,  0.9995,  0.8726,\n",
            "          0.9993,  0.7367,  0.9989,  0.9423,  0.9963, -0.7379,  0.9961, -0.9296,\n",
            "         -0.9022, -0.7847,  0.8851,  0.8767, -0.8485,  0.8878,  0.9564,  0.8368,\n",
            "          0.9997, -0.9895, -0.3410, -0.9845,  0.9355, -1.0000,  0.9964,  1.0000,\n",
            "         -0.9850, -0.9999,  0.9991, -0.8652,  0.9792, -1.0000,  0.9992, -0.9999,\n",
            "          0.5271, -0.9514, -0.9750, -0.9994, -0.9619,  0.9979,  1.0000,  0.9731,\n",
            "         -0.7881,  0.8655, -0.9839,  0.9925, -0.9529, -0.9709, -0.9993,  0.9997,\n",
            "         -0.9967, -0.9839, -0.9738,  0.9894, -0.9982,  0.8305,  0.9998, -0.9999,\n",
            "          0.9849,  0.7832, -0.9746,  0.9738,  0.9994, -0.9864, -0.8623,  1.0000,\n",
            "         -0.7904, -0.9940,  0.9997, -0.9982,  0.9952, -0.8797,  0.9815, -0.9939,\n",
            "          0.9442, -0.9349,  0.9599, -0.9989,  0.9957,  1.0000, -0.8725,  1.0000,\n",
            "         -0.9999, -0.9918, -1.0000,  0.9545,  0.9870, -0.6634,  0.9940,  0.9549,\n",
            "          0.9994,  0.8674,  0.9909,  0.9980, -0.7500,  0.9949,  0.9381,  0.9586,\n",
            "         -0.9984,  1.0000, -0.9958, -0.9870, -0.9872,  0.8477,  0.9988, -0.9570,\n",
            "          0.9994, -0.9998, -0.9862,  0.9974,  1.0000,  0.9977, -0.9883,  0.9992,\n",
            "          1.0000,  0.9931,  0.9370, -0.9506, -0.9059,  0.9985,  0.8014,  0.9147,\n",
            "          0.9822,  1.0000, -0.9993,  1.0000,  1.0000, -0.8735,  0.9623, -0.9993,\n",
            "         -0.9990, -0.9993, -0.9988,  0.9089, -0.9995, -0.9669, -0.8388,  0.9965,\n",
            "         -0.9990,  0.9652, -1.0000, -0.8406,  0.9981, -0.8779,  1.0000,  0.8682,\n",
            "         -1.0000,  0.9924, -0.9956,  0.9987, -0.8118,  0.9993,  0.9770,  0.8789,\n",
            "         -0.9875, -1.0000, -0.9998, -0.8739, -0.9990,  0.9825,  0.9997,  0.9964,\n",
            "         -0.8540,  0.8002,  0.9587,  1.0000, -1.0000, -0.8335,  0.9031, -0.9996,\n",
            "         -0.9992,  0.9990, -0.8138,  0.9882, -0.8616, -1.0000,  0.5993, -0.9719,\n",
            "          0.9985,  0.9874,  0.9996, -1.0000,  0.9998, -0.9833,  0.9975,  0.7922,\n",
            "          0.9536, -0.8859, -0.9977,  0.9993,  0.9982, -0.9557,  0.9880, -0.9039,\n",
            "          0.9965,  0.9993, -0.9938,  0.9937, -1.0000,  1.0000,  0.9932, -0.9938,\n",
            "          0.9997, -0.9991, -0.9817,  0.9995, -0.5327, -1.0000, -0.7824, -0.9961,\n",
            "          0.9948, -0.8832,  0.9973, -0.9991,  0.9855, -0.9905, -1.0000,  0.9905,\n",
            "         -0.8001,  0.9998, -0.9965,  0.8159,  0.9996, -0.9758, -0.9974, -1.0000,\n",
            "         -0.9893,  1.0000, -0.9993, -0.8468,  1.0000,  0.9997, -0.9881, -0.9905,\n",
            "         -0.9998, -1.0000, -0.8355,  0.9925, -0.6172,  0.9994, -0.9553, -0.7635,\n",
            "          0.9989,  1.0000, -0.8464,  0.8343,  0.7976, -0.9959, -1.0000, -0.9789,\n",
            "          0.7737, -1.0000,  1.0000, -0.9987,  1.0000, -0.9863,  0.9994,  0.9899,\n",
            "         -0.6611,  0.9909,  0.7828,  1.0000,  0.9989, -0.8465,  0.8129, -0.9690,\n",
            "          0.8300, -0.9929,  0.9937,  0.9649,  0.8180, -0.9960, -0.9893, -0.9967,\n",
            "         -0.9996, -0.9944,  0.8020,  0.9697,  0.9942,  0.9827,  0.9996, -0.7556,\n",
            "          0.9316, -0.8810, -1.0000,  0.9943,  0.8392,  0.9897,  0.8912, -0.9916,\n",
            "          0.9990, -0.9992,  1.0000, -0.7115, -0.9844,  0.9995,  1.0000, -1.0000,\n",
            "          0.7868, -0.9845,  0.9850,  0.9936,  0.9994, -0.9848, -0.9846,  0.9802,\n",
            "          0.9360,  0.9940,  0.9988,  0.9777, -0.3691,  0.9998,  0.9978,  0.9999,\n",
            "         -0.9987, -0.6585, -0.9492,  0.9977,  0.9958,  0.9915,  0.9923, -0.8191,\n",
            "          0.9497, -0.9854, -0.9991,  0.9803, -0.9149,  0.7794, -0.9997, -0.9663,\n",
            "         -0.9684,  1.0000, -0.9983, -0.7916,  0.9987, -0.8279,  0.8992,  0.9195,\n",
            "         -0.9995, -0.9982, -0.7883, -0.9999, -0.3089, -0.9358,  0.8821,  0.9912,\n",
            "          0.2058,  0.9887, -0.9856, -0.8418,  0.9510,  0.8835,  0.9973,  0.8397,\n",
            "         -0.6715, -0.8600,  0.9572,  0.8755, -0.7860,  0.9992, -0.9994,  1.0000,\n",
            "         -0.9070, -1.0000,  0.9994,  0.9959, -1.0000, -0.9925, -1.0000,  0.9984,\n",
            "         -0.9948,  0.9996,  0.9994, -1.0000, -1.0000, -0.9938, -0.9743, -0.8433,\n",
            "         -0.8909,  1.0000,  0.3619,  0.8400, -0.7609, -0.9977,  0.8406,  0.9996,\n",
            "         -0.9593, -1.0000,  0.9987, -0.9925,  0.9958,  0.9927, -0.9943,  0.9847,\n",
            "         -0.9948,  0.8936,  0.9995,  0.9358,  0.9861, -1.0000,  0.9998,  0.9875,\n",
            "          0.7702,  0.9828, -0.9994,  1.0000, -0.9914,  0.7585, -0.8053, -1.0000,\n",
            "         -0.9918,  0.9745,  0.9948, -0.9994,  0.8276, -0.9983, -1.0000,  0.8365,\n",
            "         -0.9975,  1.0000,  0.9948,  0.9214, -0.8673, -0.9927,  0.8350, -1.0000,\n",
            "         -0.9878, -0.9917, -0.9991,  0.9934,  0.9996,  0.9990,  0.9963,  0.9813,\n",
            "         -0.9942,  0.8918,  0.9974,  0.9982, -0.8992,  0.8788, -0.7181, -0.9994,\n",
            "         -0.9856,  0.9990,  0.9997,  0.9985, -0.9946, -0.9992,  0.8075, -0.8285,\n",
            "          0.9933, -1.0000, -0.9542, -0.7777, -1.0000,  1.0000, -1.0000, -0.8540,\n",
            "          0.9983, -0.9929,  0.9994,  0.8805, -1.0000, -1.0000, -0.9577, -0.8184,\n",
            "          0.9995, -0.7502,  0.8256,  0.9838,  0.8117,  0.9996,  0.9942,  0.9943,\n",
            "          0.9995,  1.0000,  0.9425, -0.9992, -0.9930, -1.0000, -0.9857,  0.9992,\n",
            "          0.9914,  0.9998,  0.9996,  1.0000, -1.0000,  1.0000, -1.0000,  0.9996,\n",
            "          1.0000, -0.9991,  0.9960, -1.0000,  0.9967, -0.9940,  0.7733, -0.8684,\n",
            "          0.9990, -1.0000, -0.9996,  0.8873,  0.9930,  0.9651, -0.9937,  0.9825,\n",
            "          0.9996,  0.7887,  0.9988, -0.8946, -0.9920,  1.0000,  0.9937,  0.9818,\n",
            "         -0.9984,  0.9995,  0.9879,  0.8787,  0.9938, -0.7142,  0.9710,  0.8620,\n",
            "         -0.9990, -0.8443, -1.0000, -0.9928, -0.9968,  0.9825,  0.8865,  0.8267,\n",
            "          0.8101, -0.9994,  0.9201, -1.0000,  0.9982,  0.9955,  0.8058, -0.8348,\n",
            "          0.9635, -0.9962,  1.0000,  0.9997, -1.0000,  0.7992,  0.9986,  0.9946,\n",
            "          0.9982, -0.9992, -0.7812, -0.9872, -0.9625,  0.9987,  0.8865, -0.8524,\n",
            "          0.9944, -0.9989,  0.9892, -0.9390, -0.8410,  0.9059, -0.9914,  0.7205,\n",
            "         -0.9939,  0.8605, -1.0000, -0.9939, -0.9999, -0.7202,  0.9976,  0.9783,\n",
            "          1.0000,  0.9732, -0.6287, -0.7790, -1.0000,  0.9992,  0.7993, -0.7580,\n",
            "          0.9825, -0.9996,  0.8979, -0.9989, -1.0000,  0.8873, -0.9965,  0.9044,\n",
            "          0.9839,  0.9753, -0.9982,  0.9877, -0.9180,  0.8170, -0.9905, -0.9986,\n",
            "          0.9959,  0.9799,  1.0000, -0.9989, -0.9848, -0.9982, -0.9328, -0.9928,\n",
            "          0.8873,  0.6777,  0.9974, -0.9952,  0.9761,  0.9988, -0.9987, -0.9996,\n",
            "          1.0000, -0.9934,  0.9965, -0.7931, -0.8870, -0.8578, -0.7864, -0.9908,\n",
            "         -0.9960, -0.8363, -1.0000, -0.9922,  0.9965, -0.9998, -0.9518, -0.8611,\n",
            "         -1.0000,  0.9990,  0.9955,  1.0000, -1.0000,  0.9857,  0.8489,  0.9999,\n",
            "          0.2402, -0.9263, -0.9958,  1.0000,  0.9977, -0.9924,  0.3602, -0.6888,\n",
            "         -0.7822, -0.9480, -0.9989,  0.9883,  0.9373, -0.9987, -1.0000,  1.0000,\n",
            "         -0.6479,  0.9983,  0.8612, -0.9819, -0.9876, -0.9750,  0.9923, -0.9928,\n",
            "         -1.0000,  0.8825, -1.0000, -0.9992,  0.7914,  0.9997, -1.0000, -0.9997,\n",
            "          0.7569, -1.0000, -0.9916,  0.9926,  0.9881, -0.9996, -0.9994, -0.7767,\n",
            "          1.0000,  0.9976, -0.9996, -0.9942, -0.9933,  1.0000,  0.8500,  0.8136,\n",
            "          0.9786,  0.9940,  0.9943, -0.9972, -0.9951, -0.9986, -0.9940,  0.9991,\n",
            "          0.9991, -1.0000, -0.9989, -0.9906, -0.9407,  0.9982, -0.9351, -1.0000,\n",
            "         -1.0000,  0.8824, -0.8601,  0.9981, -0.8491,  1.0000,  0.9722,  0.9130,\n",
            "         -0.9323,  0.9725,  0.7894,  0.8364, -0.8404,  1.0000,  0.9956,  0.9984]],\n",
            "       grad_fn=<TanhBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed3CFIjHc2Av"
      },
      "source": [
        "from transformers import DPRReader, DPRReaderTokenizer\n",
        "tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
        "model = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
        "encoded_inputs = tokenizer(\n",
        "        questions=[\"What is love ?\"],\n",
        "        titles=[\"Haddaway\", \"Test\"],\n",
        "        texts=[\"'What Is Love' is a song recorded by the artist Haddaway\", \"This is a test ting\"],\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "outputs = model(**encoded_inputs)\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "relevance_logits = outputs.relevance_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF67rcrWhmmr",
        "outputId": "69771712-dec7-4b3d-9880-fffa9c9f4feb"
      },
      "source": [
        "print(relevance_logits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.2456], grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH_XJ_U0h0Q8"
      },
      "source": [
        "tokenizer.decode()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}